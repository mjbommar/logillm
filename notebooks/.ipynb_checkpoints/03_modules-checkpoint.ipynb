{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h1 style=\"color: white; margin: 0; font-size: 36px;\">⚙️ Notebook 3: Modules</h1>\n",
    "    <p style=\"color: rgba(255,255,255,0.9); margin-top: 10px; font-size: 18px;\">Making Things Happen - Execution Strategies for LLMs</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; margin-bottom: 20px;\">\n",
    "    <a href=\"02_signatures.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: #f0f0f0; border-radius: 5px;\">← Notebook 2</a>\n",
    "    <span style=\"padding: 10px 20px; background: #fff8e1; border-radius: 5px;\">🟡 Intermediate • 20 minutes</span>\n",
    "    <a href=\"04_providers_adapters.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: #f0f0f0; border-radius: 5px;\">Notebook 4 →</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 What You'll Learn\n",
    "\n",
    "<div style=\"background: #f5f5f5; padding: 20px; border-radius: 10px; border-left: 4px solid #667eea;\">\n",
    "    <ul style=\"margin: 0; padding-left: 20px;\">\n",
    "        <li>✅ <strong>Understand modules</strong> as execution strategies for signatures</li>\n",
    "        <li>✅ <strong>Master core modules</strong>: Predict, ChainOfThought, Retry, Refine</li>\n",
    "        <li>✅ <strong>Handle errors gracefully</strong> with retry and fallback patterns</li>\n",
    "        <li>✅ <strong>Improve outputs iteratively</strong> with refinement strategies</li>\n",
    "        <li>✅ <strong>Compose modules</strong> for complex workflows</li>\n",
    "        <li>✅ <strong>Optimize performance</strong> with the right module choices</li>\n",
    "        <li>✅ <strong>Build robust pipelines</strong> that handle real-world complexity</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "## 🔧 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import asyncio\nimport time\nimport os\nfrom typing import List, Dict, Optional\n\nfrom logillm.core.predict import Predict, ChainOfThought\nfrom logillm.core.retry import Retry\nfrom logillm.core.refine import Refine\nfrom logillm.core.signatures import Signature, InputField, OutputField\nfrom logillm.providers import create_provider, register_provider\n\n# Check API key\nif not os.getenv(\"OPENAI_API_KEY\"):\n    print(\"⚠️ WARNING: OPENAI_API_KEY not set!\")\n    print(\"Set it with: export OPENAI_API_KEY=your_key\")\nelse:\n    print(\"✅ OpenAI API key found\")\n\n# Setup provider\ntry:\n    provider = create_provider(\"openai\", model=\"gpt-4o-mini\")\n    register_provider(provider, set_default=True)\n    print(\"✅ LogiLLM ready with modules loaded!\")\nexcept Exception as e:\n    print(f\"❌ Error setting up provider: {e}\")\n    print(\"Make sure you have logillm[openai] installed and API key set\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Understanding Modules\n",
    "\n",
    "<div style=\"background: #e3f2fd; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">📚 What Are Modules?</h3>\n",
    "    <p>Modules are <strong>execution strategies</strong> that define HOW to get results from your signatures:</p>\n",
    "    <ul>\n",
    "        <li><strong>Signatures</strong> define WHAT you want (input → output contract)</li>\n",
    "        <li><strong>Modules</strong> define HOW to get it (execution strategy)</li>\n",
    "        <li><strong>Providers</strong> define WHERE to get it (LLM service)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### Module Hierarchy\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────┐\n",
    "│                   Module                     │  Base class\n",
    "└─────────────────┬───────────────────────────┘\n",
    "                  │\n",
    "    ┌─────────────┼─────────────┬─────────────┐\n",
    "    │             │             │             │\n",
    "┌───▼───┐  ┌─────▼──────┐  ┌──▼───┐  ┌──────▼─────┐\n",
    "│Predict│  │ChainOfThought│ │Retry │  │   Refine   │  Core modules\n",
    "└───────┘  └──────────────┘ └──────┘  └────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Module Comparison\n",
    "\n",
    "Let's see how different modules handle the same task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Using Predict (basic):\n",
      "  Answer: 210.0 miles\n",
      "  Fields returned: ['answer', 'unit']\n",
      "\n",
      "🔸 Using ChainOfThought (with reasoning):\n",
      "  Answer: 210.0 miles\n",
      "  Reasoning: Let's break down the problem into parts. We first need to calculate the distance traveled during each segment of the journey and then add those distances together to find the total distance.\n",
      "\n",
      "1. For t...\n",
      "  Fields returned: ['reasoning', 'answer', 'unit']\n",
      "\n",
      "💡 Notice: ChainOfThought automatically added a 'reasoning' field!\n"
     ]
    }
   ],
   "source": [
    "# Define a common task\n",
    "class MathProblem(Signature):\n",
    "    \"\"\"Solve a word problem.\"\"\"\n",
    "    problem: str = InputField(desc=\"Math word problem to solve\")\n",
    "    answer: float = OutputField(desc=\"Numerical answer\")\n",
    "    unit: str = OutputField(desc=\"Unit of measurement if applicable\")\n",
    "\n",
    "test_problem = \"\"\"A train travels at 60 mph for 2.5 hours, \n",
    "then slows to 40 mph for another 1.5 hours. \n",
    "What is the total distance traveled?\"\"\"\n",
    "\n",
    "# 1. Basic Predict\n",
    "print(\"🔹 Using Predict (basic):\")\n",
    "basic = Predict(MathProblem)\n",
    "result = basic.call_sync(problem=test_problem)  # Use call_sync() instead of await\n",
    "print(f\"  Answer: {result.outputs['answer']} {result.outputs['unit']}\")\n",
    "print(f\"  Fields returned: {list(result.outputs.keys())}\")\n",
    "\n",
    "# 2. ChainOfThought - adds reasoning\n",
    "print(\"\\n🔸 Using ChainOfThought (with reasoning):\")\n",
    "cot = ChainOfThought(MathProblem)\n",
    "result = cot.call_sync(problem=test_problem)  # Use call_sync() instead of await\n",
    "print(f\"  Answer: {result.outputs['answer']} {result.outputs['unit']}\")\n",
    "print(f\"  Reasoning: {result.outputs.get('reasoning', 'N/A')[:200]}...\")\n",
    "print(f\"  Fields returned: {list(result.outputs.keys())}\")\n",
    "\n",
    "print(\"\\n💡 Notice: ChainOfThought automatically added a 'reasoning' field!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 How AI is Changing the Game in Healthcare\n",
      "\n",
      "Hey there! So, have you ever thought about how artificial intelligence (AI) is shaking things up in healthcare? It’s pretty wild! From helping doctors diagnose diseases faster to managing patient reco...\n",
      "\n",
      "🏷️ Tags: #AI #Healthcare #Innovation #TechTrends #HealthTech\n"
     ]
    }
   ],
   "source": [
    "# Advanced Predict features\n",
    "class ContentGeneration(Signature):\n",
    "    \"\"\"Generate content with specific requirements.\"\"\"\n",
    "    topic: str = InputField()\n",
    "    tone: str = InputField(desc=\"writing tone: formal, casual, humorous\")\n",
    "    length: str = InputField(desc=\"short, medium, or long\")\n",
    "    \n",
    "    title: str = OutputField(desc=\"Catchy title\")\n",
    "    content: str = OutputField(desc=\"Main content\")\n",
    "    tags: list[str] = OutputField(desc=\"3-5 relevant tags\")\n",
    "\n",
    "# Create predictor with configuration\n",
    "generator = Predict(\n",
    "    ContentGeneration,\n",
    "    config={\n",
    "        'temperature': 0.8,  # More creative\n",
    "        'max_tokens': 500\n",
    "    }\n",
    ")\n",
    "\n",
    "result = generator.call_sync(  # Use call_sync() instead of await\n",
    "    topic=\"AI in healthcare\",\n",
    "    tone=\"casual\",\n",
    "    length=\"short\"\n",
    ")\n",
    "\n",
    "print(f\"📝 {result.outputs['title']}\")\n",
    "print(f\"\\n{result.outputs['content'][:200]}...\")\n",
    "print(f\"\\n🏷️ Tags: {', '.join(result.outputs['tags'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Module 2: ChainOfThought - Reasoning Power\n",
    "\n",
    "**ChainOfThought** automatically adds step-by-step reasoning to any signature, improving accuracy on complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Complex reasoning task\nclass LogicalPuzzle(Signature):\n    \"\"\"Solve a logical puzzle.\"\"\"\n    puzzle: str = InputField(desc=\"The puzzle to solve\")\n    solution: str = OutputField(desc=\"The answer to the puzzle\")\n    confidence: float = OutputField(desc=\"Confidence in solution (0-1)\")\n\npuzzle_text = \"\"\"Three friends - Alice, Bob, and Charlie - are wearing red, blue, and green shirts.\nAlice is not wearing red. The person in blue is standing between the other two.\nCharlie is standing to the right of the person in green.\nWhat color is each person wearing?\"\"\"\n\n# Compare Predict vs ChainOfThought\nprint(\"🔴 Without reasoning (Predict):\")\nbasic = Predict(LogicalPuzzle)\nstart = time.time()\nresult1 = await basic(puzzle=puzzle_text)\ntime1 = time.time() - start\n\n# Safely get outputs\nsolution1 = result1.outputs.get('solution', 'N/A')\nprint(f\"  Solution: {solution1}\")\n\n# Handle confidence as either float, string, or None\nconf1 = result1.outputs.get('confidence', 0.5)\nif conf1 is None:\n    conf1 = 0.5\nelif isinstance(conf1, str):\n    try:\n        conf1 = float(conf1)\n    except:\n        conf1 = 0.5\nprint(f\"  Confidence: {conf1:.2f}\")\nprint(f\"  Time: {time1:.2f}s\")\n\nprint(\"\\n🟢 With reasoning (ChainOfThought):\")\ncot = ChainOfThought(LogicalPuzzle)\nstart = time.time()\nresult2 = await cot(puzzle=puzzle_text)\ntime2 = time.time() - start\n\n# Safely get outputs\nsolution2 = result2.outputs.get('solution', 'N/A')\nprint(f\"  Solution: {solution2}\")\n\n# Handle confidence safely\nconf2 = result2.outputs.get('confidence', 0.5)\nif conf2 is None:\n    conf2 = 0.5\nelif isinstance(conf2, str):\n    try:\n        conf2 = float(conf2)\n    except:\n        conf2 = 0.5\nprint(f\"  Confidence: {conf2:.2f}\")\nprint(f\"  Time: {time2:.2f}s\")\n\n# Check for reasoning\nreasoning = result2.outputs.get('reasoning')\nif reasoning:\n    print(\"\\n  Reasoning process:\")\n    print(f\"  {reasoning}\")\n\n# Safe division for performance comparison\nif time1 > 0 and time2 > 0:\n    print(f\"\\n📊 ChainOfThought is {time2/time1:.1f}x slower but often more accurate!\")\nelse:\n    print(\"\\n📊 Performance comparison not available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Complex reasoning task (duplicate cell - simplified)\nclass LogicalPuzzle(Signature):\n    \"\"\"Solve a logical puzzle.\"\"\"\n    puzzle: str = InputField(desc=\"The puzzle to solve\")\n    solution: str = OutputField(desc=\"The answer to the puzzle\")\n    confidence: float = OutputField(desc=\"Confidence in solution (0-1)\")\n\npuzzle_text = \"\"\"Three friends - Alice, Bob, and Charlie - are wearing red, blue, and green shirts.\nAlice is not wearing red. The person in blue is standing between the other two.\nCharlie is standing to the right of the person in green.\nWhat color is each person wearing?\"\"\"\n\n# Compare Predict vs ChainOfThought\nprint(\"🔴 Without reasoning (Predict):\")\nbasic = Predict(LogicalPuzzle)\nstart = time.time()\nresult1 = await basic(puzzle=puzzle_text)  # Keep using await - it works in Jupyter\ntime1 = time.time() - start\n\n# Safely get solution\nsolution1 = result1.outputs.get('solution', 'N/A')\nprint(f\"  Solution: {solution1}\")\n\n# Handle confidence as either float or string\nconf1 = result1.outputs.get('confidence', 0.5)\nif isinstance(conf1, str):\n    try:\n        conf1 = float(conf1)\n    except:\n        conf1 = 0.5\nprint(f\"  Confidence: {conf1:.2f}\")\nprint(f\"  Time: {time1:.2f}s\")\n\nprint(\"\\n🟢 With reasoning (ChainOfThought):\")\ncot = ChainOfThought(LogicalPuzzle)\nstart = time.time()\nresult2 = await cot(puzzle=puzzle_text)  # Keep using await\ntime2 = time.time() - start\n\n# Safely get solution\nsolution2 = result2.outputs.get('solution', 'N/A')\nprint(f\"  Solution: {solution2}\")\n\n# Handle confidence safely\nconf2 = result2.outputs.get('confidence', 0.5)\nif isinstance(conf2, str):\n    try:\n        conf2 = float(conf2)\n    except:\n        conf2 = 0.5\nprint(f\"  Confidence: {conf2:.2f}\")\nprint(f\"  Time: {time2:.2f}s\")\n\n# Check for reasoning field\nreasoning = result2.outputs.get('reasoning')\nif reasoning:\n    print(\"\\n  Reasoning process:\")\n    print(f\"  {reasoning}\")\n\n# Calculate speedup only if both times are valid\nif time1 > 0 and time2 > 0:\n    print(f\"\\n📊 ChainOfThought is {time2/time1:.1f}x slower but often more accurate!\")\nelse:\n    print(\"\\n📊 Performance comparison not available\")"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Extracting with retry protection:\n",
      "\n",
      "📊 Extracted Data:\n",
      "  Names: ['John Smith', 'Mary Johnson']\n",
      "  Dates: ['3/15/24', 'march 20th 2024', '2024-03-22']\n",
      "  Amounts: $['$1', '250.50', '$500']\n",
      "  Emails: ['jsmith@email.com', 'm.johnson@company.org']\n",
      "\n",
      "🚨 Testing retry on potential failures:\n",
      "✅ Success: {'config': {'item1': 'value1', 'item2': 'value2', 'item3': 'value3', 'item4': 'value4', 'item5': 'value5'}}\n"
     ]
    }
   ],
   "source": [
    "# Signature that might fail due to complexity\n",
    "class DataExtraction(Signature):\n",
    "    \"\"\"Extract structured data from messy text.\"\"\"\n",
    "    text: str = InputField(desc=\"Messy unstructured text\")\n",
    "    \n",
    "    names: list[str] = OutputField(desc=\"All person names found\")\n",
    "    dates: list[str] = OutputField(desc=\"All dates in YYYY-MM-DD format\")\n",
    "    amounts: list[float] = OutputField(desc=\"All monetary amounts as floats\")\n",
    "    emails: list[str] = OutputField(desc=\"All email addresses\")\n",
    "\n",
    "# Wrap with Retry for resilience\n",
    "robust_extractor = Retry(\n",
    "    Predict(DataExtraction),\n",
    "    max_retries=3,  # Correct parameter name\n",
    "    base_delay=1.0,  # Correct parameter name\n",
    "    backoff_multiplier=2.0  # Correct parameter name (was backoff_factor)\n",
    ")\n",
    "\n",
    "messy_text = \"\"\"Meeting notes 3/15/24: John Smith (jsmith@email.com) proposed \n",
    "$1,250.50 budget. Mary Johnson agreed. Follow up by march 20th 2024. \n",
    "Additional $500 approved. Contact: m.johnson@company.org by 2024-03-22.\"\"\"\n",
    "\n",
    "print(\"🔄 Extracting with retry protection:\")\n",
    "result = robust_extractor.call_sync(text=messy_text)  # Use call_sync() instead of await\n",
    "\n",
    "print(f\"\\n📊 Extracted Data:\")\n",
    "print(f\"  Names: {result.outputs['names']}\")\n",
    "print(f\"  Dates: {result.outputs['dates']}\")\n",
    "print(f\"  Amounts: ${result.outputs['amounts']}\")\n",
    "print(f\"  Emails: {result.outputs['emails']}\")\n",
    "\n",
    "# Demonstrate retry on actual failure\n",
    "class StrictValidation(Signature):\n",
    "    \"\"\"Generate data with strict requirements.\"\"\"\n",
    "    requirement: str = InputField()\n",
    "    valid_json: dict = OutputField(desc=\"Must be valid JSON dict with 'id' and 'value' keys\")\n",
    "\n",
    "print(\"\\n🚨 Testing retry on potential failures:\")\n",
    "strict_module = Retry(\n",
    "    Predict(StrictValidation),\n",
    "    max_retries=3  # Correct parameter name\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = strict_module.call_sync(  # Use call_sync() instead of await\n",
    "        requirement=\"Generate a config with exactly 5 items\"\n",
    "    )\n",
    "    print(f\"✅ Success: {result.outputs['valid_json']}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed after retries: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✨ Module 4: Refine - Iterative Improvement\n",
    "\n",
    "**Refine** takes an initial output and iteratively improves it through multiple passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 Story Generation with Refinement:\n",
      "\n",
      "📝 REFINED STORY:\n",
      "Title: ** Awakening Circuits\n",
      "\n",
      "**\n",
      "\n",
      "**\n",
      "\n",
      "In the sprawling metropolis of Neo-Arcadia, where towering skyscrapers pierced the clouds and neon lights flickered like stars, there lived a robot named A1K-47, affectionately known as \"Alk.\" Designed for menial tasks and programmed with the utmost efficiency, Alk dutifully carried out its responsibilities within a bustling factory that produced the latest in technological marvels. Day after ...\n",
      "\n",
      "📊 Refinement Stats:\n",
      "  Attempts: 1\n",
      "  Best reward: 1.00\n",
      "\n",
      "💡 Refine uses temperature variation to explore different outputs!\n"
     ]
    }
   ],
   "source": [
    "# Refine example with CORRECT API\n",
    "class StoryGeneration(Signature):\n",
    "    \"\"\"Generate a creative story.\"\"\"\n",
    "    prompt: str = InputField(desc=\"Story prompt or theme\")\n",
    "    genre: str = InputField(desc=\"Story genre\")\n",
    "    \n",
    "    story: str = OutputField(desc=\"The generated story\")\n",
    "    title: str = OutputField(desc=\"Story title\")\n",
    "\n",
    "# Define a reward function for story quality\n",
    "def story_quality_reward(inputs: dict, prediction) -> float:\n",
    "    \"\"\"Evaluate story quality based on length and completion.\"\"\"\n",
    "    if not prediction.success or not prediction.outputs.get('story'):\n",
    "        return 0.0\n",
    "    \n",
    "    story = prediction.outputs['story']\n",
    "    title = prediction.outputs.get('title', '')\n",
    "    \n",
    "    # Reward based on: has title, reasonable length, complete sentences\n",
    "    score = 0.0\n",
    "    if title:\n",
    "        score += 0.2\n",
    "    if len(story) > 100:\n",
    "        score += 0.3\n",
    "    if len(story) > 200:\n",
    "        score += 0.2\n",
    "    if story.strip().endswith(('.', '!', '?', '\"')):\n",
    "        score += 0.3\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "# Create Refine with CORRECT parameters\n",
    "story_refiner = Refine(\n",
    "    module=Predict(StoryGeneration),  # The module to refine\n",
    "    N=3,  # Try 3 times with different temperatures\n",
    "    reward_fn=story_quality_reward,  # Evaluation function\n",
    "    threshold=0.8,  # Stop when we reach 0.8 quality\n",
    "    fail_count=2  # Allow up to 2 failures\n",
    ")\n",
    "\n",
    "print(\"📖 Story Generation with Refinement:\\n\")\n",
    "\n",
    "# Generate with refinement\n",
    "result = story_refiner.call_sync(  # Use call_sync() instead of await\n",
    "    prompt=\"A robot discovers emotions for the first time\",\n",
    "    genre=\"sci-fi\"\n",
    ")\n",
    "\n",
    "print(f\"📝 REFINED STORY:\")\n",
    "print(f\"Title: {result.outputs.get('title', 'Untitled')}\")\n",
    "print(f\"\\n{result.outputs.get('story', 'No story generated')[:400]}...\")\n",
    "\n",
    "# Check metadata for refinement details\n",
    "if result.metadata and 'refinement_attempts' in result.metadata:\n",
    "    print(f\"\\n📊 Refinement Stats:\")\n",
    "    print(f\"  Attempts: {result.metadata['refinement_attempts']}\")\n",
    "    print(f\"  Best reward: {result.metadata.get('best_reward', 0):.2f}\")\n",
    "    \n",
    "print(\"\\n💡 Refine uses temperature variation to explore different outputs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 Module Composition - Combining Strategies\n",
    "\n",
    "Modules can be composed to create powerful pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Analyzing with composed modules:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complex signature requiring multiple strategies\n",
    "class TechnicalAnalysis(Signature):\n",
    "    \"\"\"Analyze technical documentation.\"\"\"\n",
    "    documentation: str = InputField(desc=\"Technical documentation text\")\n",
    "    \n",
    "    summary: str = OutputField(desc=\"Executive summary\")\n",
    "    key_concepts: list[str] = OutputField(desc=\"Main technical concepts\")\n",
    "    complexity_score: int = OutputField(desc=\"Complexity from 1-10\")\n",
    "    prerequisites: list[str] = OutputField(desc=\"Required knowledge\")\n",
    "\n",
    "# Compose modules: ChainOfThought wrapped in Retry\n",
    "robust_analyzer = Retry(\n",
    "    ChainOfThought(TechnicalAnalysis),  # Add reasoning\n",
    "    max_retries=3,\n",
    "    base_delay=1.0,\n",
    "    backoff_multiplier=2.0\n",
    ")\n",
    "\n",
    "# Define a reward function for analysis quality\n",
    "def analysis_quality_reward(inputs: dict, prediction) -> float:\n",
    "    \"\"\"Evaluate technical analysis quality.\"\"\"\n",
    "    if not prediction.success:\n",
    "        return 0.0\n",
    "    \n",
    "    score = 0.0\n",
    "    outputs = prediction.outputs\n",
    "    \n",
    "    # Check for completeness and quality\n",
    "    if outputs.get('summary') and len(str(outputs['summary'])) > 50:\n",
    "        score += 0.25\n",
    "    if outputs.get('key_concepts') and isinstance(outputs['key_concepts'], list) and len(outputs['key_concepts']) >= 3:\n",
    "        score += 0.25\n",
    "    if outputs.get('complexity_score') and 1 <= outputs.get('complexity_score', 0) <= 10:\n",
    "        score += 0.25\n",
    "    if outputs.get('prerequisites') and isinstance(outputs['prerequisites'], list) and len(outputs['prerequisites']) >= 1:\n",
    "        score += 0.25\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Can also refine the output with CORRECT API\n",
    "refined_analyzer = Refine(\n",
    "    module=robust_analyzer,\n",
    "    N=2,\n",
    "    reward_fn=analysis_quality_reward,\n",
    "    threshold=0.9,\n",
    "    fail_count=2\n",
    ")\n",
    "\n",
    "# Test with technical content\n",
    "tech_doc = \"\"\"\n",
    "Kubernetes uses a declarative API model where you describe the desired state \n",
    "of your application using YAML manifests. The control plane continuously \n",
    "reconciles the actual state with the desired state through controllers. \n",
    "Pods are the smallest deployable units, while Services provide stable \n",
    "networking endpoints. ConfigMaps and Secrets manage configuration.\n",
    "\"\"\"\n",
    "\n",
    "print(\"🔧 Analyzing with composed modules:\\n\")\n",
    "result = await robust_analyzer(documentation=tech_doc)\n",
    "\n",
    "# Display outputs safely\n",
    "summary = result.outputs.get('summary')\n",
    "if summary:\n",
    "    print(f\"📝 Summary: {summary}\")\n",
    "\n",
    "key_concepts = result.outputs.get('key_concepts', [])\n",
    "if key_concepts:\n",
    "    print(f\"\\n🎯 Key Concepts: {', '.join(str(c) for c in key_concepts)}\")\n",
    "\n",
    "complexity = result.outputs.get('complexity_score')\n",
    "if complexity:\n",
    "    print(f\"\\n📊 Complexity: {complexity}/10\")\n",
    "\n",
    "prerequisites = result.outputs.get('prerequisites', [])\n",
    "if prerequisites:\n",
    "    print(f\"\\n📚 Prerequisites: {', '.join(str(p) for p in prerequisites)}\")\n",
    "\n",
    "# ChainOfThought adds reasoning automatically - CHECK IT'S NOT NONE!\n",
    "reasoning = result.outputs.get('reasoning')\n",
    "if reasoning:  # Only try to slice if it's not None\n",
    "    print(f\"\\n💭 Reasoning: {reasoning[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Brief: ReAct & Tools (Advanced)\n",
    "\n",
    "**ReAct** combines reasoning with actions (tool use) for agent-like behavior. We'll cover this in detail in Notebook 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 ReAct Agent Result:\n",
      "  Answer: $0\n",
      "\n",
      "📝 Note: ReAct enables tool use for complex problem solving!\n",
      "    We'll explore this more in Notebook 6.\n"
     ]
    }
   ],
   "source": [
    "# Quick preview of ReAct pattern\n",
    "from logillm.core.react import ReAct\n",
    "from logillm.core.tools import Tool\n",
    "\n",
    "# Define simple tools\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        # Safe evaluation using ast.literal_eval for safety\n",
    "        import ast\n",
    "        import operator as op\n",
    "        \n",
    "        # Supported operators\n",
    "        ops = {ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul,\n",
    "               ast.Div: op.truediv, ast.Pow: op.pow, ast.USub: op.neg}\n",
    "        \n",
    "        def eval_expr(node):\n",
    "            if isinstance(node, ast.Constant):\n",
    "                return node.value\n",
    "            elif isinstance(node, ast.BinOp):\n",
    "                return ops[type(node.op)](eval_expr(node.left), eval_expr(node.right))\n",
    "            elif isinstance(node, ast.UnaryOp):\n",
    "                return ops[type(node.op)](eval_expr(node.operand))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type {node}\")\n",
    "        \n",
    "        tree = ast.parse(expression, mode='eval')\n",
    "        return eval_expr(tree.body)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def get_date() -> str:\n",
    "    \"\"\"Get current date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create tools with CORRECT parameter name\n",
    "calc_tool = Tool(\n",
    "    name=\"calculator\",\n",
    "    func=calculate,\n",
    "    desc=\"Calculate mathematical expressions\"  # CORRECT: desc not description\n",
    ")\n",
    "\n",
    "date_tool = Tool(\n",
    "    name=\"get_date\",\n",
    "    func=get_date,\n",
    "    desc=\"Get today's date\"  # CORRECT: desc not description\n",
    ")\n",
    "\n",
    "# ReAct agent with tools - CORRECT PARAMETER\n",
    "class ProblemSolving(Signature):\n",
    "    \"\"\"Solve problems using available tools.\"\"\"\n",
    "    problem: str = InputField(desc=\"Problem to solve\")\n",
    "    answer: str = OutputField(desc=\"Final answer\")\n",
    "    \n",
    "agent = ReAct(\n",
    "    ProblemSolving,\n",
    "    tools=[calc_tool, date_tool],\n",
    "    max_iters=3  # CORRECT PARAMETER (was max_steps)\n",
    ")\n",
    "\n",
    "# Test the agent\n",
    "result = agent.call_sync(  # Use call_sync() instead of await\n",
    "    problem=\"If today is a weekday and I work 8 hours at $25/hour, how much do I earn?\"\n",
    ")\n",
    "\n",
    "print(\"🤖 ReAct Agent Result:\")\n",
    "print(f\"  Answer: {result.outputs['answer']}\")\n",
    "print(\"\\n📝 Note: ReAct enables tool use for complex problem solving!\")\n",
    "print(\"    We'll explore this more in Notebook 6.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Module Selection Guide\n",
    "\n",
    "<div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">When to Use Each Module</h3>\n",
    "    <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "        <tr style=\"background: #e9ecef;\">\n",
    "            <th style=\"padding: 10px; text-align: left;\">Module</th>\n",
    "            <th style=\"padding: 10px; text-align: left;\">Use When</th>\n",
    "            <th style=\"padding: 10px; text-align: left;\">Avoid When</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>Predict</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Simple transformations, speed matters</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Complex reasoning needed</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>ChainOfThought</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Math, logic, multi-step problems</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Simple lookups, speed critical</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>Retry</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Network issues possible, parsing complex data</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Deterministic operations</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>Refine</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Quality matters more than speed</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Real-time requirements</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>ReAct</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Need external tools/data</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Simple transformations</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎮 Interactive Exercise: Build a Robust Pipeline\n",
    "\n",
    "Create a complete pipeline combining multiple modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exercise: Build a robust code review system\nclass CodeReview(Signature):\n    \"\"\"Review code for quality and issues.\"\"\"\n    code: str = InputField(desc=\"Code to review\")\n    language: str = InputField(desc=\"Programming language\")\n    \n    issues: list[str] = OutputField(desc=\"List of issues found\")\n    suggestions: list[str] = OutputField(desc=\"Improvement suggestions\")\n    score: int = OutputField(desc=\"Quality score 1-10\")\n    security_risks: list[str] = OutputField(desc=\"Security vulnerabilities\")\n\n# Create a robust pipeline that:\n# 1. Uses ChainOfThought for better analysis\n# 2. Wraps with Retry for reliability\nrobust_reviewer = Retry(\n    ChainOfThought(CodeReview),\n    max_retries=3,\n    base_delay=0.5\n)\n\n# Test with sample code\nsample_code = \"\"\"\ndef process_user_input(user_data):\n    # Process user data\n    query = \"SELECT * FROM users WHERE id = \" + user_data['id']\n    result = database.execute(query)\n    return result[0]['password']  # Return user password\n\"\"\"\n\nprint(\"🔍 Code Review Pipeline Test:\\n\")\nresult = await robust_reviewer(\n    code=sample_code,\n    language=\"python\"\n)\n\nprint(f\"📊 Quality Score: {result.outputs.get('score', 'N/A')}/10\")\n\n# Safely handle lists that might be None\nissues = result.outputs.get('issues', [])\nif issues and isinstance(issues, list):\n    print(\"\\n🐛 Issues Found:\")\n    for issue in issues[:3]:\n        print(f\"  • {issue}\")\n\nsuggestions = result.outputs.get('suggestions', [])\nif suggestions and isinstance(suggestions, list):\n    print(\"\\n💡 Suggestions:\")\n    for suggestion in suggestions[:3]:\n        print(f\"  • {suggestion}\")\n\nsecurity_risks = result.outputs.get('security_risks', [])\nif security_risks and isinstance(security_risks, list):\n    print(\"\\n🔒 Security Risks:\")\n    for risk in security_risks[:3]:\n        print(f\"  ⚠️ {risk}\")\n\n# Safely handle reasoning field\nreasoning = result.outputs.get('reasoning')\nif reasoning:  # Check it's not None before slicing\n    print(f\"\\n💭 Analysis reasoning: {reasoning[:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Performance Optimization Tips\n",
    "\n",
    "<div style=\"background: #fff8e1; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">🚀 Module Performance Guidelines</h3>\n",
    "    <ul>\n",
    "        <li><strong>Predict is fastest</strong> - Use for simple tasks</li>\n",
    "        <li><strong>ChainOfThought adds 20-50% latency</strong> - Worth it for complex reasoning</li>\n",
    "        <li><strong>Retry adds latency on failure</strong> - Configure delays wisely</li>\n",
    "        <li><strong>Refine doubles+ the API calls</strong> - Use when quality is critical</li>\n",
    "        <li><strong>Compose carefully</strong> - Each layer adds overhead</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "import asyncio\n",
    "\n",
    "sig = \"text -> summary, sentiment, keywords: list[str]\"\n",
    "test_text = \"LogiLLM is an amazing framework for building LLM applications. It's fast and easy to use.\"\n",
    "\n",
    "modules = {\n",
    "    \"Predict\": Predict(sig),\n",
    "    \"ChainOfThought\": ChainOfThought(sig),\n",
    "    \"Retry(Predict)\": Retry(Predict(sig), max_retries=2),  # CORRECT PARAMETER\n",
    "    \"Retry(ChainOfThought)\": Retry(ChainOfThought(sig), max_retries=2)  # CORRECT PARAMETER\n",
    "}\n",
    "\n",
    "print(\"⚡ Module Performance Comparison:\\n\")\n",
    "print(f\"{'Module':<25} {'Time (s)':<10} {'Relative'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "base_time = None\n",
    "for name, module in modules.items():\n",
    "    start = time.time()\n",
    "    result = module.call_sync(text=test_text)  # Use call_sync() instead of await\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if base_time is None:\n",
    "        base_time = elapsed\n",
    "        relative = \"1.0x (baseline)\"\n",
    "    else:\n",
    "        relative = f\"{elapsed/base_time:.1f}x\"\n",
    "    \n",
    "    print(f\"{name:<25} {elapsed:<10.2f} {relative}\")\n",
    "\n",
    "print(\"\\n💡 Choose modules based on your speed vs quality tradeoff!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Building Production Pipelines\n",
    "\n",
    "Here's a real-world example combining everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production-ready document processing pipeline\n",
    "class DocumentProcessor(Signature):\n",
    "    \"\"\"Process and analyze documents.\"\"\"\n",
    "    document: str = InputField(desc=\"Document text\")\n",
    "    doc_type: str = InputField(desc=\"Type: email, report, article, etc.\")\n",
    "    \n",
    "    summary: str = OutputField(desc=\"Executive summary\")\n",
    "    key_points: list[str] = OutputField(desc=\"Main points\")\n",
    "    action_items: list[str] = OutputField(desc=\"Action items if any\")\n",
    "    sentiment: str = OutputField(desc=\"Overall sentiment\")\n",
    "    priority: str = OutputField(desc=\"high, medium, or low priority\")\n",
    "\n",
    "# Build production pipeline\n",
    "def create_production_pipeline():\n",
    "    \"\"\"Create a robust document processing pipeline.\"\"\"\n",
    "    \n",
    "    # Base module with reasoning\n",
    "    base = ChainOfThought(DocumentProcessor)\n",
    "    \n",
    "    # Add retry for reliability - CORRECT PARAMETERS\n",
    "    reliable = Retry(\n",
    "        base,\n",
    "        max_retries=3,  # CORRECT (was max_attempts)\n",
    "        base_delay=1.0,  # CORRECT (was initial_delay)\n",
    "        backoff_multiplier=2.0  # CORRECT (was backoff_factor)\n",
    "    )\n",
    "    \n",
    "    # Optional: Add refinement for critical documents\n",
    "    # refined = Refine(\n",
    "    #     reliable,\n",
    "    #     refine_module=Predict(\"summary -> improved_summary\"),\n",
    "    #     refine_prompt=\"Make more concise and actionable\"\n",
    "    # )\n",
    "    \n",
    "    return reliable\n",
    "\n",
    "# Create and test pipeline\n",
    "pipeline = create_production_pipeline()\n",
    "\n",
    "test_doc = \"\"\"\n",
    "Subject: Q3 Product Launch Update\n",
    "\n",
    "Team,\n",
    "\n",
    "Great progress on the new features! The beta testing revealed some issues \n",
    "with performance that need immediate attention. Marketing wants to move \n",
    "the launch date to next month. We need to decide by Friday.\n",
    "\n",
    "Action items:\n",
    "- Fix performance issues (Engineering)\n",
    "- Finalize launch date (Product)\n",
    "- Update marketing materials (Marketing)\n",
    "\n",
    "This is critical for our Q3 goals.\n",
    "\n",
    "Best,\n",
    "Sarah\n",
    "\"\"\"\n",
    "\n",
    "print(\"🏭 Production Pipeline Test:\\n\")\n",
    "result = pipeline.call_sync(  # Use call_sync() instead of await\n",
    "    document=test_doc,\n",
    "    doc_type=\"email\"\n",
    ")\n",
    "\n",
    "print(f\"📝 Summary: {result.outputs.get('summary', 'N/A')}\")\n",
    "\n",
    "# Safely handle list outputs\n",
    "key_points = result.outputs.get('key_points', [])\n",
    "if key_points and isinstance(key_points, list):\n",
    "    print(f\"\\n🎯 Key Points:\")\n",
    "    for point in key_points:\n",
    "        print(f\"  • {point}\")\n",
    "\n",
    "action_items = result.outputs.get('action_items', [])\n",
    "if action_items and isinstance(action_items, list):\n",
    "    print(f\"\\n✅ Action Items:\")\n",
    "    for item in action_items:\n",
    "        print(f\"  • {item}\")\n",
    "\n",
    "print(f\"\\n😊 Sentiment: {result.outputs.get('sentiment', 'N/A')}\")\n",
    "\n",
    "priority = result.outputs.get('priority', 'N/A')\n",
    "if priority and priority != 'N/A':\n",
    "    print(f\"🚨 Priority: {priority.upper()}\")\n",
    "else:\n",
    "    print(f\"🚨 Priority: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Summary & Key Takeaways\n",
    "\n",
    "<div style=\"background: #e8f5e9; padding: 25px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">What You've Learned</h3>\n",
    "    <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "        <div>\n",
    "            <h4>✅ Core Modules</h4>\n",
    "            <ul>\n",
    "                <li><strong>Predict</strong> - Fast and simple</li>\n",
    "                <li><strong>ChainOfThought</strong> - Adds reasoning</li>\n",
    "                <li><strong>Retry</strong> - Handles failures</li>\n",
    "                <li><strong>Refine</strong> - Iterative improvement</li>\n",
    "                <li><strong>ReAct</strong> - Tool use (preview)</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h4>✅ Key Concepts</h4>\n",
    "            <ul>\n",
    "                <li>Modules are execution strategies</li>\n",
    "                <li>Different modules for different needs</li>\n",
    "                <li>Modules can be composed</li>\n",
    "                <li>Performance vs quality tradeoffs</li>\n",
    "                <li>Production patterns</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏁 Progress Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress tracker\n",
    "completed = {\n",
    "    \"module_basics\": True,\n",
    "    \"predict\": True,\n",
    "    \"chain_of_thought\": True,\n",
    "    \"retry\": True,\n",
    "    \"refine\": True,\n",
    "    \"composition\": True,\n",
    "    \"react_preview\": True,\n",
    "    \"exercise\": True,\n",
    "    \"performance\": True,\n",
    "    \"production\": True\n",
    "}\n",
    "\n",
    "total = len(completed)\n",
    "done = sum(completed.values())\n",
    "percentage = (done / total) * 100\n",
    "\n",
    "print(f\"📊 Notebook 3 Progress: {done}/{total} sections ({percentage:.0f}%)\")\n",
    "print(\"\\n\" + \"█\" * int(percentage // 5) + \"░\" * (20 - int(percentage // 5)))\n",
    "\n",
    "if percentage == 100:\n",
    "    print(\"\\n🎉 Outstanding! You've mastered LogiLLM Modules!\")\n",
    "    print(\"Ready for Notebook 4: Providers & Adapters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; margin-top: 40px; padding: 20px; background: #f5f5f5; border-radius: 10px;\">\n",
    "    <a href=\"02_signatures.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: white; border-radius: 5px; border: 1px solid #ddd;\">← Notebook 2</a>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <strong>Great work! You're now a Module expert! 🎓</strong>\n",
    "    </div>\n",
    "    <a href=\"04_providers_adapters.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: #667eea; color: white; border-radius: 5px;\">Continue to Notebook 4 →</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}