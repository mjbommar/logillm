{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h1 style=\"color: white; margin: 0; font-size: 36px;\">‚öôÔ∏è Notebook 3: Modules</h1>\n",
    "    <p style=\"color: rgba(255,255,255,0.9); margin-top: 10px; font-size: 18px;\">Making Things Happen - Execution Strategies for LLMs</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; margin-bottom: 20px;\">\n",
    "    <a href=\"02_signatures.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: #f0f0f0; border-radius: 5px;\">‚Üê Notebook 2</a>\n",
    "    <span style=\"padding: 10px 20px; background: #fff8e1; border-radius: 5px;\">üü° Intermediate ‚Ä¢ 20 minutes</span>\n",
    "    <a href=\"04_providers_adapters.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: #f0f0f0; border-radius: 5px;\">Notebook 4 ‚Üí</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ What You'll Learn\n",
    "\n",
    "<div style=\"background: #f5f5f5; padding: 20px; border-radius: 10px; border-left: 4px solid #667eea;\">\n",
    "    <ul style=\"margin: 0; padding-left: 20px;\">\n",
    "        <li>‚úÖ <strong>Understand modules</strong> as execution strategies for signatures</li>\n",
    "        <li>‚úÖ <strong>Master core modules</strong>: Predict, ChainOfThought, Retry, Refine</li>\n",
    "        <li>‚úÖ <strong>Handle errors gracefully</strong> with retry and fallback patterns</li>\n",
    "        <li>‚úÖ <strong>Improve outputs iteratively</strong> with refinement strategies</li>\n",
    "        <li>‚úÖ <strong>Compose modules</strong> for complex workflows</li>\n",
    "        <li>‚úÖ <strong>Optimize performance</strong> with the right module choices</li>\n",
    "        <li>‚úÖ <strong>Build robust pipelines</strong> that handle real-world complexity</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key found\n",
      "‚úÖ LogiLLM ready with modules loaded!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from logillm.core.predict import Predict, ChainOfThought\n",
    "from logillm.core.retry import Retry\n",
    "from logillm.core.refine import Refine\n",
    "from logillm.core.signatures import Signature, InputField, OutputField\n",
    "from logillm.providers import create_provider, register_provider\n",
    "\n",
    "# Check API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è WARNING: OPENAI_API_KEY not set!\")\n",
    "    print(\"Set it with: export OPENAI_API_KEY=your_key\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key found\")\n",
    "\n",
    "# Setup provider\n",
    "try:\n",
    "    provider = create_provider(\"openai\", model=\"gpt-4.1-mini\")\n",
    "    register_provider(provider, set_default=True)\n",
    "    print(\"‚úÖ LogiLLM ready with modules loaded!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error setting up provider: {e}\")\n",
    "    print(\"Make sure you have logillm[openai] installed and API key set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## üí° Important: Adapters for Type Safety\n\n<div style=\"background: #fff3cd; padding: 15px; border-radius: 8px; border-left: 4px solid #ffc107; margin: 20px 0;\">\n    <h4 style=\"margin-top: 0;\">‚ö†Ô∏è Using JSONAdapter for List Fields</h4>\n    <p>When your signature has <strong>list fields</strong> (like <code>list[str]</code> or <code>list[float]</code>), use the <strong>JSONAdapter</strong> for proper type parsing:</p>\n    <pre style=\"background: #f8f9fa; padding: 10px; border-radius: 4px;\">\nfrom logillm.core.adapters import JSONAdapter\n\n# For signatures with list fields\nmodule = Predict(MySignature, adapter=JSONAdapter())\n    </pre>\n    <p>The default ChatAdapter works great for simple types, but JSONAdapter ensures lists are properly parsed as Python lists, not strings.</p>\n</div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Module Comparison\n",
    "\n",
    "Let's see how different modules handle the same task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Using Predict (basic):\n",
      "  Answer: 195.0 miles\n",
      "  Fields returned: ['answer', 'unit']\n",
      "\n",
      "üî∏ Using ChainOfThought (with reasoning):\n",
      "  Answer: 210.0 miles\n",
      "  Reasoning: Let's think step by step to solve this problem. The train first travels at 60 mph for 2.5 hours. The distance covered in this part is speed multiplied by time: 60 mph * 2.5 hours = 150 miles. Then, th...\n",
      "  Fields returned: ['reasoning', 'answer', 'unit']\n",
      "\n",
      "üí° Notice: ChainOfThought automatically added a 'reasoning' field!\n"
     ]
    }
   ],
   "source": [
    "# Define a common task\n",
    "class MathProblem(Signature):\n",
    "    \"\"\"Solve a word problem.\"\"\"\n",
    "    problem: str = InputField(desc=\"Math word problem to solve\")\n",
    "    answer: float = OutputField(desc=\"Numerical answer\")\n",
    "    unit: str = OutputField(desc=\"Unit of measurement if applicable\")\n",
    "\n",
    "test_problem = \"\"\"A train travels at 60 mph for 2.5 hours, \n",
    "then slows to 40 mph for another 1.5 hours. \n",
    "What is the total distance traveled?\"\"\"\n",
    "\n",
    "# 1. Basic Predict\n",
    "print(\"üîπ Using Predict (basic):\")\n",
    "basic = Predict(MathProblem)\n",
    "result = await basic(problem=test_problem)\n",
    "\n",
    "# LogiLLM guarantees all output fields exist\n",
    "print(f\"  Answer: {result.outputs['answer']} {result.outputs['unit']}\")\n",
    "print(f\"  Fields returned: {list(result.outputs.keys())}\")\n",
    "\n",
    "# 2. ChainOfThought - adds reasoning\n",
    "print(\"\\nüî∏ Using ChainOfThought (with reasoning):\")\n",
    "cot = ChainOfThought(MathProblem)\n",
    "result = await cot(problem=test_problem)\n",
    "\n",
    "# All fields are guaranteed to exist\n",
    "print(f\"  Answer: {result.outputs['answer']} {result.outputs['unit']}\")\n",
    "print(f\"  Reasoning: {result.outputs['reasoning'][:200]}...\")\n",
    "print(f\"  Fields returned: {list(result.outputs.keys())}\")\n",
    "\n",
    "print(\"\\nüí° Notice: ChainOfThought automatically added a 'reasoning' field!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced Predict features\nfrom logillm.core.adapters import JSONAdapter\n\nclass ContentGeneration(Signature):\n    \"\"\"Generate content with specific requirements.\"\"\"\n    topic: str = InputField()\n    tone: str = InputField(desc=\"writing tone: formal, casual, humorous\")\n    length: str = InputField(desc=\"short, medium, or long\")\n    \n    title: str = OutputField(desc=\"Catchy title\")\n    content: str = OutputField(desc=\"Main content\")\n    tags: list[str] = OutputField(desc=\"3-5 relevant tags\")\n\n# Create predictor with JSONAdapter for proper list parsing\ngenerator = Predict(\n    ContentGeneration,\n    adapter=JSONAdapter(),  # Use JSON adapter for proper list parsing\n    config={\n        'temperature': 0.8,  # More creative\n        'max_tokens': 500\n    }\n)\n\nresult = generator.call_sync(\n    topic=\"AI in healthcare\",\n    tone=\"casual\",\n    length=\"short\"\n)\n\nprint(f\"üìù {result.outputs['title']}\")\nprint(f\"\\n{result.outputs['content'][:200]}...\")\nprint(f\"\\nüè∑Ô∏è Tags: {', '.join(result.outputs['tags'])}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Module 2: ChainOfThought - Reasoning Power\n",
    "\n",
    "**ChainOfThought** automatically adds step-by-step reasoning to any signature, improving accuracy on complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Without reasoning (Predict):\n",
      "  Solution: - Alice is wearing green,\n",
      "  - Bob is wearing red,\n",
      "  - Charlie is wearing blue.\n",
      "  Confidence: 0.50\n",
      "  Time: 2.81s\n",
      "\n",
      "üü¢ With reasoning (ChainOfThought):\n",
      "  Solution: Alice is wearing blue.\n",
      "\n",
      "Bob is wearing green.\n",
      "\n",
      "Charlie is wearing red.\n",
      "  Confidence: 0.85\n",
      "  Time: 9.22s\n",
      "\n",
      "  Reasoning process:\n",
      "  Let's think step by step to solve this problem.\n",
      "\n",
      "We have three friends: Alice, Bob, and Charlie.\n",
      "\n",
      "They are each wearing one of three colors: red, blue, or green.\n",
      "\n",
      "Clues:\n",
      "\n",
      "1. Alice is not wearing red.\n",
      "\n",
      "2. The person in blue is standing between the other two.\n",
      "\n",
      "3. Charlie is standing to the right of the person in green.\n",
      "\n",
      "First, since the blue-shirted person is standing between the other two, their order must be:\n",
      "\n",
      "Person A - Blue - Person B\n",
      "\n",
      "So, the blue shirt wearer is in the middle position.\n",
      "\n",
      "Positions (left to right):\n",
      "\n",
      "Position 1 - Position 2 (blue) - Position 3\n",
      "\n",
      "Charlie is standing to the right of the person in green, so:\n",
      "\n",
      "Green must be to the left of Charlie.\n",
      "\n",
      "So, Charlie is not on the leftmost position.\n",
      "\n",
      "Let's assign positions:\n",
      "\n",
      "Since Blue is in the middle, position 2 is blue.\n",
      "\n",
      "Positions 1 and 3 are either red or green.\n",
      "\n",
      "Positions: 1 (not blue), 2 (blue), 3 (not blue)\n",
      "\n",
      "Who can be in each position?\n",
      "\n",
      "Try position 2 (blue):\n",
      "\n",
      "Could be Alice, Bob, or Charlie.\n",
      "\n",
      "But Alice is not wearing red, so Alice could be wearing blue or green.\n",
      "\n",
      "Given that position 2 is blue, the blue person is in the middle position.\n",
      "\n",
      "Let‚Äôs suppose Alice is in position 2, wearing blue.\n",
      "\n",
      "Positions:\n",
      "\n",
      "1 - ?\n",
      "\n",
      "2 - Alice (blue)\n",
      "\n",
      "3 - ?\n",
      "\n",
      "Since Charlie is standing to the right of the person in green, the green person cannot be in position 3 (rightmost), because nobody is to their right.\n",
      "\n",
      "Charlie must be to the right of green, so:\n",
      "\n",
      "Green must be at position 1.\n",
      "\n",
      "Charlie must be at position 3.\n",
      "\n",
      "Positions:\n",
      "\n",
      "1 - green - ?\n",
      "\n",
      "2 - blue - Alice\n",
      "\n",
      "3 - ? - Charlie\n",
      "\n",
      "Remaining color for Charlie is red.\n",
      "\n",
      "Remaining person: Bob.\n",
      "\n",
      "Bob must be in position 1 because that is not taken yet.\n",
      "\n",
      "Positions:\n",
      "\n",
      "1 - Bob - green\n",
      "\n",
      "2 - Alice - blue\n",
      "\n",
      "3 - Charlie - red\n",
      "\n",
      "Check if Alice is not wearing red: Alice is wearing blue ‚Üí OK.\n",
      "\n",
      "Blue person is between other two: Yes, Alice in position 2 is blue, between positions 1 and 3.\n",
      "\n",
      "Charlie is to the right of green: Green is at 1, Charlie is at 3 ‚Üí Charlie is on the right of green ‚Üí OK.\n",
      "\n",
      "So all conditions satisfy this arrangement.\n",
      "\n",
      "üìä ChainOfThought is 3.3x slower but often more accurate!\n"
     ]
    }
   ],
   "source": [
    "# Complex reasoning task\n",
    "class LogicalPuzzle(Signature):\n",
    "    \"\"\"Solve a logical puzzle.\"\"\"\n",
    "    puzzle: str = InputField(desc=\"The puzzle to solve\")\n",
    "    solution: str = OutputField(desc=\"The answer to the puzzle\")\n",
    "    confidence: float = OutputField(desc=\"Confidence in solution (0-1)\")\n",
    "\n",
    "puzzle_text = \"\"\"Three friends - Alice, Bob, and Charlie - are wearing red, blue, and green shirts.\n",
    "Alice is not wearing red. The person in blue is standing between the other two.\n",
    "Charlie is standing to the right of the person in green.\n",
    "What color is each person wearing?\"\"\"\n",
    "\n",
    "# Compare Predict vs ChainOfThought\n",
    "print(\"üî¥ Without reasoning (Predict):\")\n",
    "basic = Predict(LogicalPuzzle)\n",
    "start = time.time()\n",
    "result1 = await basic(puzzle=puzzle_text)\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Safely get outputs\n",
    "solution1 = result1.outputs.get('solution', 'N/A')\n",
    "print(f\"  Solution: {solution1}\")\n",
    "\n",
    "# Handle confidence as either float, string, or None\n",
    "conf1 = result1.outputs.get('confidence', 0.5)\n",
    "if conf1 is None:\n",
    "    conf1 = 0.5\n",
    "elif isinstance(conf1, str):\n",
    "    try:\n",
    "        conf1 = float(conf1)\n",
    "    except:\n",
    "        conf1 = 0.5\n",
    "print(f\"  Confidence: {conf1:.2f}\")\n",
    "print(f\"  Time: {time1:.2f}s\")\n",
    "\n",
    "print(\"\\nüü¢ With reasoning (ChainOfThought):\")\n",
    "cot = ChainOfThought(LogicalPuzzle)\n",
    "start = time.time()\n",
    "result2 = await cot(puzzle=puzzle_text)\n",
    "time2 = time.time() - start\n",
    "\n",
    "# Safely get outputs\n",
    "solution2 = result2.outputs.get('solution', 'N/A')\n",
    "print(f\"  Solution: {solution2}\")\n",
    "\n",
    "# Handle confidence safely\n",
    "conf2 = result2.outputs.get('confidence', 0.5)\n",
    "if conf2 is None:\n",
    "    conf2 = 0.5\n",
    "elif isinstance(conf2, str):\n",
    "    try:\n",
    "        conf2 = float(conf2)\n",
    "    except:\n",
    "        conf2 = 0.5\n",
    "print(f\"  Confidence: {conf2:.2f}\")\n",
    "print(f\"  Time: {time2:.2f}s\")\n",
    "\n",
    "# Check for reasoning\n",
    "reasoning = result2.outputs.get('reasoning')\n",
    "if reasoning:\n",
    "    print(\"\\n  Reasoning process:\")\n",
    "    print(f\"  {reasoning}\")\n",
    "\n",
    "# Safe division for performance comparison\n",
    "if time1 > 0 and time2 > 0:\n",
    "    print(f\"\\nüìä ChainOfThought is {time2/time1:.1f}x slower but often more accurate!\")\n",
    "else:\n",
    "    print(\"\\nüìä Performance comparison not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Without reasoning (Predict):\n",
      "  Solution: N/A\n",
      "  Confidence: 0.50\n",
      "  Time: 6.10s\n",
      "\n",
      "üü¢ With reasoning (ChainOfThought):\n",
      "  Solution: N/A\n",
      "  Confidence: 0.50\n",
      "  Time: 9.07s\n",
      "\n",
      "  Reasoning process:\n",
      "  Let's analyze the puzzle step by step.\n",
      "\n",
      "üìä ChainOfThought is 1.5x slower but often more accurate!\n"
     ]
    }
   ],
   "source": [
    "# Complex reasoning task (duplicate cell - simplified)\n",
    "class LogicalPuzzle(Signature):\n",
    "    \"\"\"Solve a logical puzzle.\"\"\"\n",
    "    puzzle: str = InputField(desc=\"The puzzle to solve\")\n",
    "    solution: str = OutputField(desc=\"The answer to the puzzle\")\n",
    "    confidence: float = OutputField(desc=\"Confidence in solution (0-1)\")\n",
    "\n",
    "puzzle_text = \"\"\"Three friends - Alice, Bob, and Charlie - are wearing red, blue, and green shirts.\n",
    "Alice is not wearing red. The person in blue is standing between the other two.\n",
    "Charlie is standing to the right of the person in green.\n",
    "What color is each person wearing?\"\"\"\n",
    "\n",
    "# Compare Predict vs ChainOfThought\n",
    "print(\"üî¥ Without reasoning (Predict):\")\n",
    "basic = Predict(LogicalPuzzle)\n",
    "start = time.time()\n",
    "result1 = await basic(puzzle=puzzle_text)  # Keep using await - it works in Jupyter\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Safely get solution\n",
    "solution1 = result1.outputs.get('solution', 'N/A')\n",
    "print(f\"  Solution: {solution1}\")\n",
    "\n",
    "# Handle confidence as either float or string\n",
    "conf1 = result1.outputs.get('confidence', 0.5)\n",
    "if isinstance(conf1, str):\n",
    "    try:\n",
    "        conf1 = float(conf1)\n",
    "    except:\n",
    "        conf1 = 0.5\n",
    "print(f\"  Confidence: {conf1:.2f}\")\n",
    "print(f\"  Time: {time1:.2f}s\")\n",
    "\n",
    "print(\"\\nüü¢ With reasoning (ChainOfThought):\")\n",
    "cot = ChainOfThought(LogicalPuzzle)\n",
    "start = time.time()\n",
    "result2 = await cot(puzzle=puzzle_text)  # Keep using await\n",
    "time2 = time.time() - start\n",
    "\n",
    "# Safely get solution\n",
    "solution2 = result2.outputs.get('solution', 'N/A')\n",
    "print(f\"  Solution: {solution2}\")\n",
    "\n",
    "# Handle confidence safely\n",
    "conf2 = result2.outputs.get('confidence', 0.5)\n",
    "if isinstance(conf2, str):\n",
    "    try:\n",
    "        conf2 = float(conf2)\n",
    "    except:\n",
    "        conf2 = 0.5\n",
    "print(f\"  Confidence: {conf2:.2f}\")\n",
    "print(f\"  Time: {time2:.2f}s\")\n",
    "\n",
    "# Check for reasoning field\n",
    "reasoning = result2.outputs.get('reasoning')\n",
    "if reasoning:\n",
    "    print(\"\\n  Reasoning process:\")\n",
    "    print(f\"  {reasoning}\")\n",
    "\n",
    "# Calculate speedup only if both times are valid\n",
    "if time1 > 0 and time2 > 0:\n",
    "    print(f\"\\nüìä ChainOfThought is {time2/time1:.1f}x slower but often more accurate!\")\n",
    "else:\n",
    "    print(\"\\nüìä Performance comparison not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Signature that might fail due to complexity\nfrom logillm.core.adapters import JSONAdapter\n\nclass DataExtraction(Signature):\n    \"\"\"Extract structured data from messy text.\"\"\"\n    text: str = InputField(desc=\"Messy unstructured text\")\n    \n    names: list[str] = OutputField(desc=\"All person names found\")\n    dates: list[str] = OutputField(desc=\"All dates in YYYY-MM-DD format\")\n    amounts: list[float] = OutputField(desc=\"All monetary amounts as floats\")\n    emails: list[str] = OutputField(desc=\"All email addresses\")\n\n# Wrap with Retry for resilience, use JSONAdapter for proper list parsing\nrobust_extractor = Retry(\n    Predict(DataExtraction, adapter=JSONAdapter()),\n    max_retries=3,\n    base_delay=1.0,\n    backoff_multiplier=2.0\n)\n\nmessy_text = \"\"\"Meeting notes 3/15/24: John Smith (jsmith@email.com) proposed \n$1,250.50 budget. Mary Johnson agreed. Follow up by march 20th 2024. \nAdditional $500 approved. Contact: m.johnson@company.org by 2024-03-22.\"\"\"\n\nprint(\"üîÑ Extracting with retry protection (using JSONAdapter):\")\nresult = robust_extractor.call_sync(text=messy_text)\n\nprint(f\"\\nüìä Extracted Data:\")\nprint(f\"  Names: {result.outputs['names']}\")\nprint(f\"  Dates: {result.outputs['dates']}\")\nprint(f\"  Amounts: ${', $'.join(str(amt) for amt in result.outputs['amounts'])}\")\nprint(f\"  Emails: {result.outputs['emails']}\")\n\n# Demonstrate retry on actual failure\nclass StrictValidation(Signature):\n    \"\"\"Generate data with strict requirements.\"\"\"\n    requirement: str = InputField()\n    valid_json: dict = OutputField(desc=\"Must be valid JSON dict with 'id' and 'value' keys\")\n\nprint(\"\\nüö® Testing retry on potential failures:\")\nstrict_module = Retry(\n    Predict(StrictValidation, adapter=JSONAdapter()),\n    max_retries=3\n)\n\ntry:\n    result = strict_module.call_sync(\n        requirement=\"Generate a config with exactly 5 items\"\n    )\n    print(f\"‚úÖ Success: {result.outputs['valid_json']}\")\nexcept Exception as e:\n    print(f\"‚ùå Failed after retries: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ú® Module 4: Refine - Iterative Improvement\n",
    "\n",
    "**Refine** takes an initial output and iteratively improves it through multiple passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Story Generation with Refinement:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Refine example with CORRECT API\n",
    "class StoryGeneration(Signature):\n",
    "    \"\"\"Generate a creative story.\"\"\"\n",
    "    prompt: str = InputField(desc=\"Story prompt or theme\")\n",
    "    genre: str = InputField(desc=\"Story genre\")\n",
    "    \n",
    "    story: str = OutputField(desc=\"The generated story\")\n",
    "    title: str = OutputField(desc=\"Story title\")\n",
    "\n",
    "# Define a reward function for story quality\n",
    "def story_quality_reward(inputs: dict, prediction) -> float:\n",
    "    \"\"\"Evaluate story quality based on length and completion.\"\"\"\n",
    "    if not prediction.success or not prediction.outputs.get('story'):\n",
    "        return 0.0\n",
    "    \n",
    "    story = prediction.outputs['story']\n",
    "    title = prediction.outputs.get('title', '')\n",
    "    \n",
    "    # Reward based on: has title, reasonable length, complete sentences\n",
    "    score = 0.0\n",
    "    if title:\n",
    "        score += 0.2\n",
    "    if len(story) > 100:\n",
    "        score += 0.3\n",
    "    if len(story) > 200:\n",
    "        score += 0.2\n",
    "    if story.strip().endswith(('.', '!', '?', '\"')):\n",
    "        score += 0.3\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "# Create Refine with CORRECT parameters\n",
    "story_refiner = Refine(\n",
    "    module=Predict(StoryGeneration),  # The module to refine\n",
    "    N=3,  # Try 3 times with different temperatures\n",
    "    reward_fn=story_quality_reward,  # Evaluation function\n",
    "    threshold=0.8,  # Stop when we reach 0.8 quality\n",
    "    fail_count=2  # Allow up to 2 failures\n",
    ")\n",
    "\n",
    "print(\"üìñ Story Generation with Refinement:\\n\")\n",
    "\n",
    "# Generate with refinement\n",
    "result = story_refiner.call_sync(  # Use call_sync() instead of await\n",
    "    prompt=\"A robot discovers emotions for the first time\",\n",
    "    genre=\"sci-fi\"\n",
    ")\n",
    "\n",
    "print(f\"üìù REFINED STORY:\")\n",
    "print(f\"Title: {result.outputs.get('title', 'Untitled')}\")\n",
    "print(f\"\\n{result.outputs.get('story', 'No story generated')[:400]}...\")\n",
    "\n",
    "# Check metadata for refinement details\n",
    "if result.metadata and 'refinement_attempts' in result.metadata:\n",
    "    print(f\"\\nüìä Refinement Stats:\")\n",
    "    print(f\"  Attempts: {result.metadata['refinement_attempts']}\")\n",
    "    print(f\"  Best reward: {result.metadata.get('best_reward', 0):.2f}\")\n",
    "    \n",
    "print(\"\\nüí° Refine uses temperature variation to explore different outputs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Module Composition - Combining Strategies\n",
    "\n",
    "Modules can be composed to create powerful pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Complex signature requiring multiple strategies\nclass TechnicalAnalysis(Signature):\n    \"\"\"Analyze technical documentation.\"\"\"\n    documentation: str = InputField(desc=\"Technical documentation text\")\n    \n    summary: str = OutputField(desc=\"Executive summary\")\n    key_concepts: list[str] = OutputField(desc=\"Main technical concepts\")\n    complexity_score: int = OutputField(desc=\"Complexity from 1-10\")\n    prerequisites: list[str] = OutputField(desc=\"Required knowledge\")\n\n# Compose modules: ChainOfThought wrapped in Retry\nrobust_analyzer = Retry(\n    ChainOfThought(TechnicalAnalysis),  # Add reasoning\n    max_retries=3,\n    base_delay=1.0,\n    backoff_multiplier=2.0\n)\n\n# Test with technical content\ntech_doc = \"\"\"\nKubernetes uses a declarative API model where you describe the desired state \nof your application using YAML manifests. The control plane continuously \nreconciles the actual state with the desired state through controllers. \nPods are the smallest deployable units, while Services provide stable \nnetworking endpoints. ConfigMaps and Secrets manage configuration.\n\"\"\"\n\nprint(\"üîß Analyzing with composed modules:\\n\")\nresult = await robust_analyzer(documentation=tech_doc)\n\n# Check if the call succeeded\nif not result.success:\n    print(f\"‚ùå Analysis failed: {result.error}\")\n    print(\"Make sure your API key is set and you have credits\")\nelse:\n    print(f\"üìù Summary: {result.outputs['summary']}\")\n    \n    # Note: Due to a current LogiLLM limitation, list fields might come back as strings\n    # Here's a workaround to parse them:\n    def parse_list_field(value):\n        if isinstance(value, list):\n            return value\n        elif isinstance(value, str):\n            # Try to parse comma-separated or bullet lists\n            if ',' in value:\n                return [item.strip() for item in value.split(',')]\n            elif '\\n' in value:\n                return [line.strip('- ‚Ä¢* ') for line in value.split('\\n') if line.strip()]\n            else:\n                return [value]  # Single item\n        return []\n    \n    key_concepts = parse_list_field(result.outputs['key_concepts'])\n    print(f\"\\nüéØ Key Concepts: {', '.join(key_concepts)}\")\n    \n    print(f\"\\nüìä Complexity: {result.outputs['complexity_score']}/10\")\n    \n    prerequisites = parse_list_field(result.outputs['prerequisites'])\n    print(f\"\\nüìö Prerequisites: {', '.join(prerequisites)}\")\n    \n    # ChainOfThought adds reasoning automatically\n    print(f\"\\nüí≠ Reasoning: {result.outputs['reasoning'][:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Brief: ReAct & Tools (Advanced)\n",
    "\n",
    "**ReAct** combines reasoning with actions (tool use) for agent-like behavior. We'll cover this in detail in Notebook 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview of ReAct pattern\n",
    "from logillm.core.react import ReAct\n",
    "from logillm.core.tools import Tool\n",
    "\n",
    "# Define simple tools\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        # Safe evaluation using ast.literal_eval for safety\n",
    "        import ast\n",
    "        import operator as op\n",
    "        \n",
    "        # Supported operators\n",
    "        ops = {ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul,\n",
    "               ast.Div: op.truediv, ast.Pow: op.pow, ast.USub: op.neg}\n",
    "        \n",
    "        def eval_expr(node):\n",
    "            if isinstance(node, ast.Constant):\n",
    "                return node.value\n",
    "            elif isinstance(node, ast.BinOp):\n",
    "                return ops[type(node.op)](eval_expr(node.left), eval_expr(node.right))\n",
    "            elif isinstance(node, ast.UnaryOp):\n",
    "                return ops[type(node.op)](eval_expr(node.operand))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type {node}\")\n",
    "        \n",
    "        tree = ast.parse(expression, mode='eval')\n",
    "        return eval_expr(tree.body)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def get_date() -> str:\n",
    "    \"\"\"Get current date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create tools with CORRECT parameter name\n",
    "calc_tool = Tool(\n",
    "    name=\"calculator\",\n",
    "    func=calculate,\n",
    "    desc=\"Calculate mathematical expressions\"  # CORRECT: desc not description\n",
    ")\n",
    "\n",
    "date_tool = Tool(\n",
    "    name=\"get_date\",\n",
    "    func=get_date,\n",
    "    desc=\"Get today's date\"  # CORRECT: desc not description\n",
    ")\n",
    "\n",
    "# ReAct agent with tools - CORRECT PARAMETER\n",
    "class ProblemSolving(Signature):\n",
    "    \"\"\"Solve problems using available tools.\"\"\"\n",
    "    problem: str = InputField(desc=\"Problem to solve\")\n",
    "    answer: str = OutputField(desc=\"Final answer\")\n",
    "    \n",
    "agent = ReAct(\n",
    "    ProblemSolving,\n",
    "    tools=[calc_tool, date_tool],\n",
    "    max_iters=3  # CORRECT PARAMETER (was max_steps)\n",
    ")\n",
    "\n",
    "# Test the agent\n",
    "result = agent.call_sync(  # Use call_sync() instead of await\n",
    "    problem=\"If today is a weekday and I work 8 hours at $25/hour, how much do I earn?\"\n",
    ")\n",
    "\n",
    "print(\"ü§ñ ReAct Agent Result:\")\n",
    "print(f\"  Answer: {result.outputs['answer']}\")\n",
    "print(\"\\nüìù Note: ReAct enables tool use for complex problem solving!\")\n",
    "print(\"    We'll explore this more in Notebook 6.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Module Selection Guide\n",
    "\n",
    "<div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">When to Use Each Module</h3>\n",
    "    <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "        <tr style=\"background: #e9ecef;\">\n",
    "            <th style=\"padding: 10px; text-align: left;\">Module</th>\n",
    "            <th style=\"padding: 10px; text-align: left;\">Use When</th>\n",
    "            <th style=\"padding: 10px; text-align: left;\">Avoid When</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>Predict</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Simple transformations, speed matters</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Complex reasoning needed</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>ChainOfThought</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Math, logic, multi-step problems</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Simple lookups, speed critical</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>Retry</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Network issues possible, parsing complex data</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Deterministic operations</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>Refine</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Quality matters more than speed</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Real-time requirements</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\"><strong>ReAct</strong></td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Need external tools/data</td>\n",
    "            <td style=\"padding: 10px; border-top: 1px solid #dee2e6;\">Simple transformations</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Exercise: Build a Robust Pipeline\n",
    "\n",
    "Create a complete pipeline combining multiple modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exercise: Build a robust code review system\nfrom logillm.core.adapters import JSONAdapter\n\nclass CodeReview(Signature):\n    \"\"\"Review code for quality and issues.\"\"\"\n    code: str = InputField(desc=\"Code to review\")\n    language: str = InputField(desc=\"Programming language\")\n    \n    issues: list[str] = OutputField(desc=\"List of issues found\")\n    suggestions: list[str] = OutputField(desc=\"Improvement suggestions\")\n    score: int = OutputField(desc=\"Quality score 1-10\")\n    security_risks: list[str] = OutputField(desc=\"Security vulnerabilities\")\n\n# Create a robust pipeline that:\n# 1. Uses ChainOfThought for better analysis\n# 2. Uses JSONAdapter for proper list parsing\n# 3. Wraps with Retry for reliability\nrobust_reviewer = Retry(\n    ChainOfThought(CodeReview, adapter=JSONAdapter()),  # Use JSON adapter\n    max_retries=3,\n    base_delay=0.5\n)\n\n# Test with sample code\nsample_code = \"\"\"\ndef process_user_input(user_data):\n    # Process user data\n    query = \"SELECT * FROM users WHERE id = \" + user_data['id']\n    result = database.execute(query)\n    return result[0]['password']  # Return user password\n\"\"\"\n\nprint(\"üîç Code Review Pipeline Test (with JSONAdapter):\\n\")\nresult = await robust_reviewer(\n    code=sample_code,\n    language=\"python\"\n)\n\nprint(f\"üìä Quality Score: {result.outputs['score']}/10\")\n\n# With JSONAdapter, lists should be properly parsed\nissues = result.outputs['issues']\nprint(\"\\nüêõ Issues Found:\")\nfor issue in issues[:3]:\n    print(f\"  ‚Ä¢ {issue}\")\n\nsuggestions = result.outputs['suggestions']\nprint(\"\\nüí° Suggestions:\")\nfor suggestion in suggestions[:3]:\n    print(f\"  ‚Ä¢ {suggestion}\")\n\nsecurity_risks = result.outputs['security_risks']\nprint(\"\\nüîí Security Risks:\")\nfor risk in security_risks[:3]:\n    print(f\"  ‚ö†Ô∏è {risk}\")\n\n# ChainOfThought adds reasoning\nprint(f\"\\nüí≠ Analysis reasoning: {result.outputs['reasoning'][:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance Optimization Tips\n",
    "\n",
    "<div style=\"background: #fff8e1; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">üöÄ Module Performance Guidelines</h3>\n",
    "    <ul>\n",
    "        <li><strong>Predict is fastest</strong> - Use for simple tasks</li>\n",
    "        <li><strong>ChainOfThought adds 20-50% latency</strong> - Worth it for complex reasoning</li>\n",
    "        <li><strong>Retry adds latency on failure</strong> - Configure delays wisely</li>\n",
    "        <li><strong>Refine doubles+ the API calls</strong> - Use when quality is critical</li>\n",
    "        <li><strong>Compose carefully</strong> - Each layer adds overhead</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "import asyncio\n",
    "\n",
    "sig = \"text -> summary, sentiment, keywords: list[str]\"\n",
    "test_text = \"LogiLLM is an amazing framework for building LLM applications. It's fast and easy to use.\"\n",
    "\n",
    "modules = {\n",
    "    \"Predict\": Predict(sig),\n",
    "    \"ChainOfThought\": ChainOfThought(sig),\n",
    "    \"Retry(Predict)\": Retry(Predict(sig), max_retries=2),  # CORRECT PARAMETER\n",
    "    \"Retry(ChainOfThought)\": Retry(ChainOfThought(sig), max_retries=2)  # CORRECT PARAMETER\n",
    "}\n",
    "\n",
    "print(\"‚ö° Module Performance Comparison:\\n\")\n",
    "print(f\"{'Module':<25} {'Time (s)':<10} {'Relative'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "base_time = None\n",
    "for name, module in modules.items():\n",
    "    start = time.time()\n",
    "    result = module.call_sync(text=test_text)  # Use call_sync() instead of await\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if base_time is None:\n",
    "        base_time = elapsed\n",
    "        relative = \"1.0x (baseline)\"\n",
    "    else:\n",
    "        relative = f\"{elapsed/base_time:.1f}x\"\n",
    "    \n",
    "    print(f\"{name:<25} {elapsed:<10.2f} {relative}\")\n",
    "\n",
    "print(\"\\nüí° Choose modules based on your speed vs quality tradeoff!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Building Production Pipelines\n",
    "\n",
    "Here's a real-world example combining everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Production-ready document processing pipeline\nfrom logillm.core.adapters import JSONAdapter\n\nclass DocumentProcessor(Signature):\n    \"\"\"Process and analyze documents.\"\"\"\n    document: str = InputField(desc=\"Document text\")\n    doc_type: str = InputField(desc=\"Type: email, report, article, etc.\")\n    \n    summary: str = OutputField(desc=\"Executive summary\")\n    key_points: list[str] = OutputField(desc=\"Main points\")\n    action_items: list[str] = OutputField(desc=\"Action items if any\")\n    sentiment: str = OutputField(desc=\"Overall sentiment\")\n    priority: str = OutputField(desc=\"high, medium, or low priority\")\n\n# Build production pipeline\ndef create_production_pipeline():\n    \"\"\"Create a robust document processing pipeline.\"\"\"\n    \n    # Base module with reasoning and JSON adapter for proper list parsing\n    base = ChainOfThought(DocumentProcessor, adapter=JSONAdapter())\n    \n    # Add retry for reliability\n    reliable = Retry(\n        base,\n        max_retries=3,\n        base_delay=1.0,\n        backoff_multiplier=2.0\n    )\n    \n    # Optional: Add refinement for critical documents\n    # refined = Refine(\n    #     module=reliable,\n    #     N=2,\n    #     reward_fn=lambda i, p: 0.8 if p.success else 0.0\n    # )\n    \n    return reliable\n\n# Create and test pipeline\npipeline = create_production_pipeline()\n\ntest_doc = \"\"\"\nSubject: Q3 Product Launch Update\n\nTeam,\n\nGreat progress on the new features! The beta testing revealed some issues \nwith performance that need immediate attention. Marketing wants to move \nthe launch date to next month. We need to decide by Friday.\n\nAction items:\n- Fix performance issues (Engineering)\n- Finalize launch date (Product)\n- Update marketing materials (Marketing)\n\nThis is critical for our Q3 goals.\n\nBest,\nSarah\n\"\"\"\n\nprint(\"üè≠ Production Pipeline Test (with JSONAdapter):\\n\")\nresult = pipeline.call_sync(\n    document=test_doc,\n    doc_type=\"email\"\n)\n\nprint(f\"üìù Summary: {result.outputs['summary']}\")\n\n# With JSONAdapter, lists are properly parsed\nkey_points = result.outputs['key_points']\nprint(f\"\\nüéØ Key Points:\")\nfor point in key_points:\n    print(f\"  ‚Ä¢ {point}\")\n\naction_items = result.outputs['action_items']\nprint(f\"\\n‚úÖ Action Items:\")\nfor item in action_items:\n    print(f\"  ‚Ä¢ {item}\")\n\nprint(f\"\\nüòä Sentiment: {result.outputs['sentiment']}\")\nprint(f\"üö® Priority: {result.outputs['priority'].upper()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary & Key Takeaways\n",
    "\n",
    "<div style=\"background: #e8f5e9; padding: 25px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"margin-top: 0;\">What You've Learned</h3>\n",
    "    <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "        <div>\n",
    "            <h4>‚úÖ Core Modules</h4>\n",
    "            <ul>\n",
    "                <li><strong>Predict</strong> - Fast and simple</li>\n",
    "                <li><strong>ChainOfThought</strong> - Adds reasoning</li>\n",
    "                <li><strong>Retry</strong> - Handles failures</li>\n",
    "                <li><strong>Refine</strong> - Iterative improvement</li>\n",
    "                <li><strong>ReAct</strong> - Tool use (preview)</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h4>‚úÖ Key Concepts</h4>\n",
    "            <ul>\n",
    "                <li>Modules are execution strategies</li>\n",
    "                <li>Different modules for different needs</li>\n",
    "                <li>Modules can be composed</li>\n",
    "                <li>Performance vs quality tradeoffs</li>\n",
    "                <li>Production patterns</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ Progress Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress tracker\n",
    "completed = {\n",
    "    \"module_basics\": True,\n",
    "    \"predict\": True,\n",
    "    \"chain_of_thought\": True,\n",
    "    \"retry\": True,\n",
    "    \"refine\": True,\n",
    "    \"composition\": True,\n",
    "    \"react_preview\": True,\n",
    "    \"exercise\": True,\n",
    "    \"performance\": True,\n",
    "    \"production\": True\n",
    "}\n",
    "\n",
    "total = len(completed)\n",
    "done = sum(completed.values())\n",
    "percentage = (done / total) * 100\n",
    "\n",
    "print(f\"üìä Notebook 3 Progress: {done}/{total} sections ({percentage:.0f}%)\")\n",
    "print(\"\\n\" + \"‚ñà\" * int(percentage // 5) + \"‚ñë\" * (20 - int(percentage // 5)))\n",
    "\n",
    "if percentage == 100:\n",
    "    print(\"\\nüéâ Outstanding! You've mastered LogiLLM Modules!\")\n",
    "    print(\"Ready for Notebook 4: Providers & Adapters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; margin-top: 40px; padding: 20px; background: #f5f5f5; border-radius: 10px;\">\n",
    "    <a href=\"02_signatures.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: white; border-radius: 5px; border: 1px solid #ddd;\">‚Üê Notebook 2</a>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <strong>Great work! You're now a Module expert! üéì</strong>\n",
    "    </div>\n",
    "    <a href=\"04_providers_adapters.ipynb\" style=\"text-decoration: none; padding: 10px 20px; background: #667eea; color: white; border-radius: 5px;\">Continue to Notebook 4 ‚Üí</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}